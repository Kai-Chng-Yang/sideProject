{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4167231007.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 23\u001b[1;36m\u001b[0m\n\u001b[1;33m    data = body.find('div', {<!-- -->'id': '7d'})    # 找到div标签且id = 7d\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# weather.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "def getHTMLtext(url):     \n",
    " \"\"\"请求获得网页内容\"\"\"\n",
    " try:         \n",
    "  r = requests.get(url, timeout = 30)         \n",
    "  r.raise_for_status()         \n",
    "  r.encoding = r.apparent_encoding         \n",
    "  print(\"成功访问\")         \n",
    "  return r.text     \n",
    " except:         \n",
    "  print(\"访问错误\")         \n",
    "  return\" \" \n",
    "\n",
    "def get_content(html):\n",
    " \"\"\"处理得到有用信息保存数据文件\"\"\"\n",
    " final = []          # 初始化一个列表保存数据\n",
    " bs = BeautifulSoup(html, \"html.parser\")  # 创建BeautifulSoup对象\n",
    " body = bs.body\n",
    " data = body.find('div', {<!-- -->'id': '7d'})    # 找到div标签且id = 7d\n",
    " # 下面爬取当天的数据\n",
    " data2 = body.find_all('div',{<!-- -->'class':'left-div'})\n",
    " text = data2[2].find('script').string  \n",
    " text = text[text.index('=')+1 :-2]   # 移除改var data=将其变为json数据\n",
    " jd = json.loads(text)\n",
    " dayone = jd['od']['od2']     # 找到当天的数据\n",
    " final_day = []           # 存放当天的数据\n",
    " count = 0\n",
    " for i in dayone:\n",
    "  temp = []\n",
    "  if count <=23:\n",
    "   temp.append(i['od21'])     # 添加时间\n",
    "   temp.append(i['od22'])     # 添加当前时刻温度\n",
    "   temp.append(i['od24'])     # 添加当前时刻风力方向\n",
    "   temp.append(i['od25'])     # 添加当前时刻风级\n",
    "   temp.append(i['od26'])     # 添加当前时刻降水量\n",
    "   temp.append(i['od27'])     # 添加当前时刻相对湿度\n",
    "   temp.append(i['od28'])     # 添加当前时刻控制质量\n",
    "   #print(temp)\n",
    "   final_day.append(temp)\n",
    "  count = count +1\n",
    " # 下面爬取7天的数据 \n",
    " ul = data.find('ul')      # 找到所有的ul标签\n",
    " li = ul.find_all('li')      # 找到左右的li标签\n",
    " i = 0     # 控制爬取的天数\n",
    " for day in li:          # 遍历找到的每一个li\n",
    "     if i < 7 and i > 0:\n",
    "         temp = []          # 临时存放每天的数据\n",
    "         date = day.find('h1').string     # 得到日期\n",
    "         date = date[0:date.index('日')]   # 取出日期号\n",
    "         temp.append(date)            \n",
    "         inf = day.find_all('p')      # 找出li下面的p标签,提取第一个p标签的值，即天气\n",
    "         temp.append(inf[0].string)\n",
    "\n",
    "         tem_low = inf[1].find('i').string   # 找到最低气温\n",
    "\n",
    "         if inf[1].find('span') is None:   # 天气预报可能没有最高气温\n",
    "             tem_high = None\n",
    "         else:\n",
    "             tem_high = inf[1].find('span').string  # 找到最高气温\n",
    "         temp.append(tem_low[:-1])\n",
    "         if tem_high[-1] == '℃':\n",
    "          temp.append(tem_high[:-1])\n",
    "         else:\n",
    "          temp.append(tem_high)\n",
    "\n",
    "         wind = inf[2].find_all('span')  # 找到风向\n",
    "         for j in wind:\n",
    "          temp.append(j['title'])\n",
    "\n",
    "         wind_scale = inf[2].find('i').string # 找到风级\n",
    "         index1 = wind_scale.index('级')\n",
    "         temp.append(int(wind_scale[index1-1:index1]))\n",
    "         final.append(temp)\n",
    "     i = i + 1\n",
    " return final_day,final\n",
    " #print(final)    \n",
    "def get_content2(html):\n",
    " \"\"\"处理得到有用信息保存数据文件\"\"\"\n",
    " final = []                # 初始化一个列表保存数据\n",
    " bs = BeautifulSoup(html, \"html.parser\")        # 创建BeautifulSoup对象\n",
    " body = bs.body\n",
    " data = body.find('div', {<!-- -->'id': '15d'})          # 找到div标签且id = 15d\n",
    " ul = data.find('ul')            # 找到所有的ul标签\n",
    " li = ul.find_all('li')            # 找到左右的li标签\n",
    " final = []\n",
    " i = 0                 # 控制爬取的天数\n",
    " for day in li:               # 遍历找到的每一个li\n",
    "     if i < 8:\n",
    "         temp = []               # 临时存放每天的数据\n",
    "         date = day.find('span',{<!-- -->'class':'time'}).string    # 得到日期\n",
    "         date = date[date.index('（')+1:-2]        # 取出日期号\n",
    "         temp.append(date)  \n",
    "         weather = day.find('span',{<!-- -->'class':'wea'}).string    # 找到天气\n",
    "         temp.append(weather)\n",
    "         tem = day.find('span',{<!-- -->'class':'tem'}).text      # 找到温度\n",
    "         temp.append(tem[tem.index('/')+1:-1])     # 找到最低气温\n",
    "         temp.append(tem[:tem.index('/')-1])      # 找到最高气温\n",
    "         wind = day.find('span',{<!-- -->'class':'wind'}).string    # 找到风向\n",
    "         if '转' in wind:           # 如果有风向变化\n",
    "          temp.append(wind[:wind.index('转')])\n",
    "          temp.append(wind[wind.index('转')+1:])\n",
    "         else:             # 如果没有风向变化，前后风向一致\n",
    "          temp.append(wind)\n",
    "          temp.append(wind)\n",
    "         wind_scale = day.find('span',{<!-- -->'class':'wind1'}).string    # 找到风级\n",
    "         index1 = wind_scale.index('级')\n",
    "         temp.append(int(wind_scale[index1-1:index1]))\n",
    "          \n",
    "         final.append(temp)\n",
    " return final\n",
    "\n",
    "def write_to_csv(file_name, data, day=14):\n",
    " \"\"\"保存为csv文件\"\"\"\n",
    " with open(file_name, 'a', errors='ignore', newline='') as f:\n",
    "  if day == 14:\n",
    "   header = ['日期','天气','最低气温','最高气温','风向1','风向2','风级']\n",
    "  else:\n",
    "   header = ['小时','温度','风力方向','风级','降水量','相对湿度','空气质量']\n",
    "  f_csv = csv.writer(f)\n",
    "  f_csv.writerow(header)\n",
    "  f_csv.writerows(data)\n",
    "\n",
    "def main():\n",
    " \"\"\"主函数\"\"\"\n",
    " print(\"Weather test\")\n",
    " # 珠海\n",
    " url1 = 'http://www.weather.com.cn/weather/101280701.shtml'    # 7天天气中国天气网\n",
    " url2 = 'http://www.weather.com.cn/weather15d/101280701.shtml' # 8-15天天气中国天气网\n",
    " \n",
    " html1 = getHTMLtext(url1)\n",
    " data1, data1_7 = get_content(html1)  # 获得1-7天和当天的数据\n",
    "\n",
    " html2 = getHTMLtext(url2)\n",
    " data8_14 = get_content2(html2)   # 获得8-14天数据\n",
    " data14 = data1_7 + data8_14\n",
    " #print(data)\n",
    " write_to_csv('weather14.csv',data14,14) # 保存为csv文件\n",
    " write_to_csv('weather1.csv',data1,1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    " main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
